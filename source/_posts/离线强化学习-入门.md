---
title: 离线强化学习入门
categories: 强化学习 离线强化学习
date: 2023-11-8 19:45:23
---

在前面的学习中，我们已经对强化学习有了不少了解。无论是**在线策略**（on-policy）算法还是**离线策略**（off-policy）算法，都有一个共同点：智能体在训练过程中可以不断和环境交互，得到新的反馈数据。二者的区别主要在于在线策略算法会直接使用这些反馈数据，而离线策略算法会先将数据存入经验回放池中，需要时再采样。然而，<u>在现实生活中的许多场景下，让尚未学习好的智能体和环境交互可能会导致危险发生，或是造成巨大损失。</u>例如，在训练自动驾驶的规控智能体时，如果让智能体从零开始和真实环境进行交互，那么在训练的最初阶段，它操控的汽车无疑会横冲直撞，造成各种事故。再例如，在推荐系统中，用户的反馈往往比较滞后，统计智能体策略的回报需要很长时间。而如果策略存在问题，早期的用户体验不佳，就会导致用户流失等后果。因此，<u>**离线强化学习**（offline reinforcement learning）的目标是，在智能体不和环境交互的情况下，仅从已经收集好的确定的数据集中，通过强化学习算法得到比较好的策略。</u>

## 离线强化学习很难学习的原因

### **数据质量（拟合与过拟合）**

深度学习的成功可以归结为数据集（ImageNet等）的准确强大，offline RL也不例外

强化学习在与环境中交互学习的过程中，最关键的一个问题便是“**Exploration vs Exploitation Dilemma**”， Exploration是为了收集更多信息（尝试一些不可能等），而Exploitation则根据当前信息做出最佳决策。

这两者可以说对一个算法的训练精度、速度等各方面有重要影响，**而Offline RL算法中需要完全的依赖于静态数据集 D，但是没有办法提高exploration，因为不和环境进行交互，就无法知道探索得到的数据是否有效，是否有高质量的奖励反馈等**，所以 Offline RL不可能通过探索发现高奖励的区域。

### **数据质量（拟合与过拟合）**

深度学习的成功可以归结为数据集（ImageNet等）的准确强大，offline RL也不例外

### 分布偏移(Distribution shift)

**分布偏移(Distribution shift)** 在监督学习中一般指的是训练分布与测试分布不同，在离线强化学习中指的是训练策略与行为策略不一致。

在Offline RL中obejctive函数为
$$
\min_QE_{(\mathbf{s},\mathbf{a})\sim\pi_\beta(\mathbf{s},\mathbf{a})}\left[\left(Q(\mathbf{s},\mathbf{a})-(r(\mathbf{s},\mathbf{a})+E_{\mathbf{a}'\sim\pi_{\mathrm{sew}}}\left[Q\left(\mathbf{s}',\mathbf{a}'\right)\right]\right)^2\right]
$$
其中的 $\pi_\mathrm{\beta}$ 是我们从offline data中学习的策略，而我们希望 $\pi_\beta( \mathbf{a} \mid \mathbf{s} ) = \pi_\mathrm{new}( \mathbf{a} \mid \mathbf{s} ) $, 这样就可以达到学习目的了。

学习策略$\pi(a|s)$ 的过程中可能会进入和训练分布差距很远的状态，这将导致$d^{\pi_\beta}(s)$ 和$d^{\pi_{\eta ew}}(s)$差距非常大。那么，当策略在$t$ 时刻遇到了分布之外 (数据集中没见过) 的状态时，策略在之后的 $(H-t)$ 个时刻就有可能不断的犯错，所以累计误差$O(H)$，而且每一个时间步，都有可能进入分布外的状态，造成整体误差为$O(H^2)$, 这将导致算法难以收敛。



Online与Offline的区别在于是否与环境实时交互，标准的的RL算法通过反复试错来学习如何执行任务，并在探索与利用之间进行平衡达到更好的表现，而Offline RL要求智能体从固定的数据集汇总进行学习，不能进行探索，因此Offline研究的是如何最大限度的利用静态的离线数据集来训练RL智能体。



































参考:

1. [动手学强化学习](https://hrl.boyuai.com/chapter/3/%E7%A6%BB%E7%BA%BF%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0)
2. [离线强化学习(Offline RL)系列1：离线强化学习原理](https://zhuanlan.zhihu.com/p/489470062)