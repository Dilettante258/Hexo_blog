---
title: 强化学习基础-时序差分算法
categories: 强化学习
date: 2023-10-7 20:34:00
mathjax: true
---

动态规划算法适用于已知马尔可夫决策过程的情况，可以直接解出最优价值或策略。但在大部分情况下，马尔可夫决策过程的状态转移概率是未知的，这时就需要使用无模型的强化学习算法。无模型的强化学习算法不需要事先知道环境的奖励函数和状态转移函数，而是通过与环境交互采样数据来学习。

无模型的强化学习算法基于时序差分（temporal difference，TD）学习，其中两个经典算法是Sarsa和Q-learning。Sarsa算法是一种在线策略学习算法，它使用当前策略下采样得到的样本进行学习。Q-learning算法是一种离线策略学习算法，它使用经验回放池将之前采样得到的样本收集起来再次利用。

离线策略学习使用历史数据进行学习，可以更好地利用历史数据，并具有更小的样本复杂度。因此，离线策略学习在实际应用中更为广泛。



